{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218136dd-dc5d-4097-881d-5c0a84ccb614",
   "metadata": {},
   "source": [
    "# Building a Recommender "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2caff-a295-4ee2-a4cb-487c18612531",
   "metadata": {},
   "source": [
    "*In this project, I will be creating  a spelling recommender that uses nltk to find words similar to the misspelling.* \n",
    "Have you ever searched for a book on Amazon but mistyped the title? Instead of a frustrating dead-end, This pops up below the search bar: **'Did you mean...?'** This is the power of spelling recommender systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90b63e-e48f-4db0-ad9f-d54e1fe2ba78",
   "metadata": {},
   "source": [
    "### Business Value\n",
    "* By correcting spelling mistakes, advanced recommender versions of this one below ensure that users find what they are looking for more efficiently\n",
    "* From a user experience perspective, users feel better supported and find the platform more user-friendly when their typos are rightfully corrected, which can increase customer satisfaction.\n",
    "* *Sales!* Correcting search terms can directly better match users with products they 'actually\" wish to buy, which would increase *conversion rates*, sales and less search abandonment!\n",
    "* Reduced Search Abandonment: By providing correct alternatives to misspelled queries, these systems decrease the likelihood of users abandoning the search out of frustration or inability to find what they are looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21d5e9d-5798-4ef0-b9e7-c969deff3873",
   "metadata": {},
   "source": [
    "## Text Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceb28288-c229-4920-9beb-fe7eb023ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm', 'neural', 'network', 'data', 'science', 'machine', 'learning', 'statistics', 'python']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.metrics.distance import jaccard_distance, edit_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import cmudict\n",
    "\n",
    "\n",
    "correct_spellings = words.words()\n",
    "# Phonetic dictionary\n",
    "prondict = cmudict.dict()\n",
    "\n",
    "def spelling_recommender(misspelled_words):\n",
    "    recommendations = []\n",
    "\n",
    "    for misspelled_word in misspelled_words:\n",
    "        # Generating phonetic code for the misspelled word\n",
    "        phonetic_misspelled = [phonetic for word, phonetic in prondict.items() if misspelled_word in word]\n",
    "\n",
    "        # Initial filtering\n",
    "        candidates = [word for word in correct_spellings if word[0].lower() == misspelled_word[0].lower()]\n",
    "\n",
    "        if phonetic_misspelled:\n",
    "            candidates = [word for word in candidates if word in prondict and any(\n",
    "                ph in phonetic_misspelled for ph in prondict[word])]\n",
    "\n",
    "        if len(candidates) < 10:\n",
    "            candidates = [word for word in correct_spellings if word[0].lower() == misspelled_word[0].lower()]\n",
    "\n",
    "        # Calculateing combined metric for the rest of candidate words\n",
    "        distances = ((edit_distance(misspelled_word, word) +\n",
    "                      jaccard_distance(set(ngrams(misspelled_word, n=3)), set(ngrams(word, n=3))), word)\n",
    "                     for word in candidates)\n",
    "        \n",
    "        # Let's find the candidate with the minimum combined distance\n",
    "        closest_word = min(distances, key=lambda x: x[0])[1]\n",
    "        recommendations.append(closest_word)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Testing the recommender with a list of common data science words\n",
    "test_words = ['algoritm', 'neaural', 'netwrok', 'dat', 'scienc', 'mchine', 'learnin', 'statistcs', 'pythn']\n",
    "recommendations = spelling_recommender(test_words)\n",
    "\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285cd686-524e-4679-860b-9172e86c15f0",
   "metadata": {},
   "source": [
    "#### Challenges & Learnings\n",
    "The development of this spelling recommender underwent many iterations to improve its robustness and general applicability. Initially based on edit distance, I had to further refine it to include Jaccard distance and dynamic n-gram sizing to better address diverse spelling errors and difficulties handling short words. For example, after learning new text mining techniques, I later updated the project by adding phonetic similarity instead of filtering only by the initial letter and similar length. These modifications helped ensure the recommender could handle a wide range of input scenarios.\n",
    "\n",
    "#### Acknowledged Limitations\n",
    "* The model struggles with very short words\n",
    "* The recommender does not consider the context in which words are used ( in testing this system, I used the data science context), which can lead to recommendations that are syntactically correct but semantically inappropriate for the given text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cfce1-c500-45e0-afd2-9fa1816b7141",
   "metadata": {},
   "source": [
    "##### *Thank You for Reviewing This Project*\n",
    "\n",
    "I appreciate you taking the time to go through my work. Please feel free to reach out if you have any questions, suggestions, or would like to discuss any aspects of this project further.\n",
    "\n",
    "Best Regards,\n",
    "\n",
    "Chaymae\n",
    "##### *Chaymaejawhar@gmail.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b32446-4f73-4aaa-b459-32e3a154586f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
